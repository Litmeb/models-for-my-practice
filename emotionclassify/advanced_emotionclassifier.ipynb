{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "79eecd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "40004e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "min_freq=10\n",
    "max_len=50\n",
    "batch_size=100\n",
    "embed_size=300\n",
    "learningrate=0.0001\n",
    "dropout=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "8a3a6b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['joy', 'fear', 'anger', 'love']\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "emotionlist=['sadness','joy','love','anger','fear','surprise']\n",
    "emotiondict={emotionlist[i]:i for i in range(len(emotionlist))}\n",
    "def idx2emotion(idx):\n",
    "    if not isinstance(idx,(tuple,list)):\n",
    "        return emotionlist[idx]\n",
    "    return [idx2emotion(i) for i in idx]\n",
    "def emotion2idx(emotion):\n",
    "    if not isinstance(emotion,(tuple,list)):\n",
    "        return emotiondict[emotion]\n",
    "    return [emotion2idx(i) for i in emotion]\n",
    "print(idx2emotion([1,4,3,2]))\n",
    "print(emotion2idx(['sadness','joy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "a02d484c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "416809\n",
      "sadness:0.2907494799776396\n",
      "joy:0.3384451871240784\n",
      "love:0.0829012809224369\n",
      "anger:0.13751382527728528\n",
      "fear:0.11446969715145307\n",
      "surprise:0.03592052954710671\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle(\"merged_training.pkl\")\n",
    "df=df.reset_index(drop=True)\n",
    "print(len(df))\n",
    "for i in emotionlist:\n",
    "    print(f'{i}:{len(df[df.emotions==i])/len(df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "3b6f9642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '<unk>', 'i', 'feel', 'and', 'to', 'the', 'a', 'feeling', 'that']\n",
      "2 [2, 3]\n",
      "15334\n"
     ]
    }
   ],
   "source": [
    "class Vocab():\n",
    "    def __init__(self,tokens,min_freq=0):\n",
    "        self.token_freq = {}\n",
    "        for sentence in tokens:\n",
    "            for token in sentence.split():\n",
    "                if token not in self.token_freq:\n",
    "                    self.token_freq[token] = 1\n",
    "                else:\n",
    "                    self.token_freq[token] += 1\n",
    "        self.itos = [\"<pad>\",\"<unk>\"]\n",
    "        for token,freq in self.token_freq.items():\n",
    "            if freq >= min_freq:\n",
    "                self.itos.append(token)\n",
    "        self.itos[2:]=sorted(self.itos[2:],key=lambda x:self.token_freq[x],reverse=True)\n",
    "        self.stoi = {token:idx for idx,token in enumerate(self.itos)}\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "    def __getitem__(self,idx):\n",
    "        if not isinstance(idx,(list,tuple)):\n",
    "            return self.itos[idx] if idx!=0 else ''\n",
    "        return [self.__getitem__(i) for i in idx]\n",
    "    def tokens2idx(self,tokens):\n",
    "        if not isinstance(tokens,(list,tuple)):\n",
    "            if ' ' in tokens:\n",
    "                return self.tokens2idx(tokens.split())\n",
    "            if tokens in self.stoi:\n",
    "                return self.stoi[tokens]\n",
    "            return self.stoi['<unk>']\n",
    "        return [self.tokens2idx(i) for i in tokens]\n",
    "vocab=Vocab(df.text,min_freq=min_freq)\n",
    "print(vocab[(0,1,2,3,4,5,6,7,8,9)])\n",
    "print(vocab.stoi['i'],vocab.tokens2idx(['i','feel']))\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ac0fd5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     text emotions\n",
      "0       i feel awful about it too because it s my job ...  sadness\n",
      "1                                   im alone i feel awful  sadness\n",
      "2                i was feeling a little low few days back  sadness\n",
      "3       i also feel disillusioned that someone who cla...  sadness\n",
      "4       i wish you knew every word i write i write for...  sadness\n",
      "...                                                   ...      ...\n",
      "556191  i just feel like screaming at myself for being...     love\n",
      "556192  i always end up watching one of his dvd s as i...      joy\n",
      "556193  i can t seem to describe how i am feeling in a...      joy\n",
      "556194  i will never let you feel unloved for a second...  sadness\n",
      "556195  i could sense that he was uncomfortable when h...     fear\n",
      "\n",
      "[556196 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df1=df[:350000]\n",
    "dfsad=df1[df1.emotions=='sadness']\n",
    "dfanger=df1[df1.emotions=='anger']\n",
    "dffear=df1[df1.emotions=='fear']\n",
    "dflove=df1[df1.emotions=='love']\n",
    "dfsurprise=df1[df1.emotions=='surprise']\n",
    "df2=pd.concat([dfsad[:7000],dfanger,dfanger[:16000],dffear,dffear[:27000],dflove,dflove,dflove[:10000],df1],ignore_index=True)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "662fd613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([   2,  119,    3,  852,    9,  147,   75, 5076,    5, 1504,    6,  985,\n",
      "          29,    2,   39,   21,    7, 4094,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0]), 'sadness')\n",
      "['i', 'also', 'feel', 'disillusioned', 'that', 'someone', 'who', 'claimed', 'to', 'value', 'the', 'truth', 'as', 'i', 'do', 'was', 'a', 'fraud', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "i was feeling a little low few days back sadness\n"
     ]
    }
   ],
   "source": [
    "class dataset(data.Dataset):\n",
    "    def __init__(self,datasource,vocab):\n",
    "        self.set=datasource.reset_index(drop=True)\n",
    "        self.vocab=vocab\n",
    "    def __getitem__(self, index):\n",
    "        c=vocab.tokens2idx(self.set.text[index])\n",
    "        if not isinstance(c,list):\n",
    "            c=[c]\n",
    "        if len(c)>=max_len:\n",
    "            c=c[:max_len]\n",
    "        else:\n",
    "            c=c+[0]*(max_len-len(c))\n",
    "        return (torch.tensor(c),self.set.emotions[index])\n",
    "    def __len__(self):\n",
    "        return len(self.set)\n",
    "trainset=dataset(df2,vocab)\n",
    "testset=dataset(df[350000:],vocab)\n",
    "load_trainset=data.DataLoader(trainset,batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "load_testset=data.DataLoader(testset,batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "print(trainset[3])\n",
    "print(vocab[list(trainset[3][0])])\n",
    "print(df.text[3],df.emotions[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "8ecbffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 位置编码\n",
    "class PositionalEncoding(nn.Module):\n",
    "    # 初始化函数，接收隐藏单元数量、dropout率和最大序列长度作为输入\n",
    "    def __init__(self, num_hiddens, max_len=1000):\n",
    "        # 调用父类的初始化函数\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        # 创建一个dropout层，用于随机丢弃输入的元素\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # 创建一个形状为(1, max_len, num_hiddens)的位置编码张量P，初始化为全0\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        # 生成位置编码矩阵X，其中每一行表示一个位置的编码，编码方式采用sin和cos函数\n",
    "        # 编码公式：X[i, j] = sin(i / 10000^(2j / num_hiddens)) 或 cos(i / 10000^(2j / num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(\n",
    "            -1, 1) / torch.pow(10000, \n",
    "                               torch.arange(0, num_hiddens, 2, dtype=torch.float32) /\n",
    "                               num_hiddens)\n",
    "        # 将位置编码矩阵中的偶数维度的元素替换为sin函数的结果\n",
    "        self.P[:,:,0::2] = torch.sin(X)\n",
    "        # 将位置编码矩阵中的奇数维度的元素替换为cos函数的结果\n",
    "        self.P[:,:,1::2] = torch.cos(X)\n",
    "    # 前向传播函数，接收输入张量X作为输入\n",
    "    def forward(self, X):\n",
    "        # 将位置编码张量P与输入张量X相加，并将结果移动到与X相同的设备上\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        # 对相加后的结果应用dropout，并返回结果\n",
    "        return self.dropout(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "9a311771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2175,  0.1191,  0.3686, -0.4585,  0.6218,  0.1661]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class emotion(nn.Module):\n",
    "    def __init__(self,vocab_size,embed_size,num_classes,dropout=0.5):\n",
    "        super(emotion,self).__init__()\n",
    "        self.embedding=nn.Embedding(vocab_size,embed_size)\n",
    "        self.pos=PositionalEncoding(embed_size,max_len=max_len)\n",
    "        self.multiheadattention1=nn.TransformerEncoderLayer(embed_size,5,batch_first=True,dropout=dropout)\n",
    "        self.multiheadattention2=nn.TransformerEncoderLayer(embed_size,5,batch_first=True,dropout=dropout)\n",
    "        self.multiheadattention3=nn.TransformerEncoderLayer(embed_size,5,batch_first=True,dropout=dropout)\n",
    "        self.fc=nn.Linear(embed_size,num_classes)\n",
    "        #self.softmax=nn.Softmax()\n",
    "    def forward(self,x):\n",
    "        mask=~(x==0)\n",
    "        x=self.embedding(x)\n",
    "        x=self.pos(x)\n",
    "        x=self.multiheadattention1(x,src_key_padding_mask=mask)\n",
    "        x=self.multiheadattention2(x,src_key_padding_mask=mask)\n",
    "        x=self.multiheadattention3(x,src_key_padding_mask=mask)\n",
    "        x=torch.sum(x,dim=1)/torch.sum(mask,dim=1).unsqueeze(dim=1)\n",
    "        x=self.fc(x)\n",
    "        #x=self.softmax(x)\n",
    "        return x\n",
    "model=emotion(len(vocab),embed_size,len(emotionlist),dropout=dropout)\n",
    "model.to(device=device)\n",
    "a=torch.ones(1,5,device=device).long()\n",
    "print(model(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2761c429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fear\n"
     ]
    }
   ],
   "source": [
    "def predict1sentence(model,sentence,vocab):\n",
    "    model.eval()\n",
    "    c=vocab.tokens2idx(sentence.lower().split())\n",
    "    if not isinstance(c,list):\n",
    "        c=[c]\n",
    "    if len(c)>=max_len:\n",
    "        c=c[:max_len]\n",
    "    else:\n",
    "        c=c+[0]*(max_len-len(c))\n",
    "    c=torch.tensor(c)\n",
    "    c=c.to(device=device)\n",
    "    # print(c.unsqueeze(dim=0).shape)\n",
    "    prediction=model(c.unsqueeze(dim=0))\n",
    "    # print(c)\n",
    "    # print(prediction)\n",
    "    # print(torch.argmax(prediction,dim=1))\n",
    "    return idx2emotion(torch.argmax(prediction,dim=1))\n",
    "print(predict1sentence(model,'For all the hours I spent in the gym working and training and Vanessa you holding down the family the way that you have I cant theres no way that I can thank you enough so from the bottom of my heart thank you And what can I say Mamba out',vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "899a29ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(60282, device='cuda:0'), tensor(0.9024, device='cuda:0'), tensor([19096., 22501.,  6611.,  8324.,  8800.,  1468.]), tensor([19277., 22767.,  5536.,  9164.,  7701.,  2355.]), tensor([0.9906, 0.9883, 1.1942, 0.9083, 1.1427, 0.6234]))\n"
     ]
    }
   ],
   "source": [
    "def get_acc(model,load_testset):\n",
    "    model.eval()\n",
    "    correct=0\n",
    "    total=0\n",
    "    countclass=torch.zeros(6)\n",
    "    totalclass=torch.zeros(6)\n",
    "    for datapair in load_testset:\n",
    "        text,label=datapair\n",
    "        text=text.to(device)\n",
    "        label=torch.tensor(emotion2idx(label))\n",
    "        label=label.to(device)\n",
    "        answer=model(text)\n",
    "        answer=torch.argmax(answer,dim=1)\n",
    "        for i in range(6):\n",
    "            countclass[i]+=torch.count_nonzero(answer==torch.tensor([i],device=device)).item()\n",
    "            totalclass[i]+=torch.count_nonzero(label==torch.tensor([i],device=device)).item()\n",
    "        correct+=torch.count_nonzero(answer==label)\n",
    "        total+=batch_size\n",
    "        \n",
    "    return correct,correct/total,countclass,totalclass,countclass/totalclass\n",
    "print(get_acc(model,load_testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c7acf29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(60279, device='cuda:0'), tensor(0.9024, device='cuda:0'), tensor([18438., 22071.,  6945.,  9840.,  7099.,  2407.]), tensor([19277., 22765.,  5535.,  9167.,  7701.,  2355.]), tensor([0.9565, 0.9695, 1.2547, 1.0734, 0.9218, 1.0221]))\n",
      "(tensor(501208, device='cuda:0'), tensor(0.9013, device='cuda:0'), tensor([108548., 121418., 100637., 115961.,  93027.,  16509.]), tensor([108886., 118279.,  97036., 112280., 107004.,  12615.]), tensor([0.9969, 1.0265, 1.0371, 1.0328, 0.8694, 1.3087]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\22846\\AppData\\Local\\Temp\\ipykernel_54912\\2797634214.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  weight=nn.functional.softmax(-freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(inf, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1000\n",
      "tensor(0.2628, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2000\n",
      "tensor(0.2623, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3000\n",
      "tensor(0.2612, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "4000\n",
      "tensor(0.2600, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "5000\n",
      "tensor(0.2588, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=learningrate)\n",
    "for epoch in range(1):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        acc=get_acc(model,load_testset=load_testset)\n",
    "        print(acc)\n",
    "        acc=get_acc(model,load_trainset)\n",
    "        print(acc)\n",
    "        freq=acc[-1]\n",
    "        weight=nn.functional.softmax(-freq)\n",
    "    loss=nn.CrossEntropyLoss(weight=weight*6)\n",
    "    loss.to(device=device)\n",
    "    model.train()\n",
    "    totalloss=0\n",
    "    for number,datapair in enumerate(load_trainset):\n",
    "        # print(number)\n",
    "        text,label=datapair\n",
    "        text=text.to(device)\n",
    "        label=torch.tensor(emotion2idx(label))\n",
    "        # print(label)\n",
    "        label=label.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        result=model(text)\n",
    "        # print(result)\n",
    "        trainloss=loss(result,label)\n",
    "        trainloss.backward()\n",
    "        optimizer.step()\n",
    "        totalloss+=trainloss\n",
    "        if number%1000==0:\n",
    "            print(number)\n",
    "            print(totalloss/number)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a578c845",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'6classes,emotion,withposinfo,acc=9024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342d8281",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('5classes,emotion',weights_only=False)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3573df34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "import random\n",
    "start=random.randint(1,50000)\n",
    "for i in range(start,start+20):\n",
    "    p=testset[i][0]\n",
    "    p=p.to(device=device)\n",
    "    predict=model(p.unsqueeze(dim=0))\n",
    "    predictemotion=idx2emotion(torch.argmax(predict,dim=1))\n",
    "    sentence=vocab[testset[i][0].tolist()]\n",
    "    try:\n",
    "        sentence.remove('')\n",
    "    except:\n",
    "        pass\n",
    "    sentence=' '.join(sentence)\n",
    "    print(f'原句：{sentence}')\n",
    "    print(f'预测感情：{predictemotion},实际感情：{testset[i][1]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
